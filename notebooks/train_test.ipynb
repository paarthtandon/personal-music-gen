{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:\\\\Users\\\\Paarth Tandon\\\\Desktop\\\\repos\\\\personal-music-gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.models import MusicGen\n",
    "from personal_musicgen.data.datasets import AudioDataset\n",
    "from personal_musicgen.model_utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paarth tandon\\desktop\\repos\\personal-music-gen\\libs\\audiocraft\\audiocraft\\models\\musicgen.py:116: UserWarning: MusicGen pretrained model relying on deprecated checkpoint mapping. Please use full pre-trained id instead: facebook/musicgen-small\n",
      "  warnings.warn(\n",
      "c:\\Users\\Paarth Tandon\\Desktop\\repos\\personal-music-gen\\.venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "data = AudioDataset('../data/chunks_no_voice/')\n",
    "model = MusicGen.get_pretrained('small')\n",
    "model.lm = model.lm.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(Subset(data, list(range(100))), batch_size=1)\n",
    "acc_steps = 4\n",
    "optimizer = AdamW(\n",
    "    model.lm.parameters(),\n",
    "    lr=1e-5,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.1,\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_step(\n",
    "        model: MusicGen,\n",
    "        optimizer: AdamW,\n",
    "        scaler: GradScaler,\n",
    "        dataloader: DataLoader,\n",
    "        grad_acc_steps: int\n",
    ") -> dict:\n",
    "    device = model.device\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (audio_fns, label_fns) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        codes_l = []\n",
    "        text_l = []\n",
    "\n",
    "        for audio_fn, label_fn in zip(audio_fns, label_fns):\n",
    "            codes = encode_audio(model, audio_fn)\n",
    "            codes_l.append(codes)\n",
    "            with open(label_fn, 'r') as label_f:\n",
    "                text_l.append(label_f.read().strip())\n",
    "        \n",
    "        codes = torch.cat(codes_l, dim=0).to(device)\n",
    "\n",
    "        attributes, _ = model._prepare_tokens_and_attributes(text_l, None)\n",
    "        conditional_vector = get_contitional_vector(model, attributes)\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            lm_output = model.lm.compute_predictions(\n",
    "                codes=codes,\n",
    "                conditions=[],\n",
    "                condition_tensors=conditional_vector\n",
    "            )\n",
    "\n",
    "            loss = compute_masked_loss(lm_output, codes)\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            print(loss.item())\n",
    "\n",
    "            if (i + 1) % grad_acc_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.lm.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:05<09:41,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.240298271179199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:09<07:11,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.163398027420044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:12<06:08,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.828628420829773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:15<05:35,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.915003538131714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:21<07:00,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.784695625305176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:24<06:16,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.107187271118164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:27<05:41,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.934700965881348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:30<05:28,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.523026466369629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:37<06:43,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7372982501983643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:40<06:07,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.068359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:43<05:25,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.520743370056152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:46<05:03,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.414567947387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:52<06:18,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3525471687316895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:55<05:46,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.097527027130127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:58<05:12,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.004128932952881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:01<04:53,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.071561336517334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:08<06:04,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.316941976547241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:11<05:31,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.182795763015747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:14<04:55,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.207293510437012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:17<04:36,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.255553722381592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:23<05:40,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.413774490356445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:26<05:10,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.387679576873779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:29<04:39,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.030332565307617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:32<04:21,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5116868019104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:39<05:25,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.005823612213135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:42<04:55,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.141480922698975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:45<04:23,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.549711227416992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:48<04:07,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2668843269348145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:54<05:05,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.746333360671997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:57<04:36,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0812788009643555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:00<04:08,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4870195388793945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:03<03:53,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.761338233947754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:09<04:50,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.87001371383667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:13<04:24,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2783734798431396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:15<03:55,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9527554512023926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:18<03:41,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7286298274993896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:21<04:10,  3.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Paarth Tandon\\Desktop\\repos\\personal-music-gen\\notebooks\\train_test.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_step(model, optimizer, scaler, dataloader, acc_steps)\n",
      "\u001b[1;32mc:\\Users\\Paarth Tandon\\Desktop\\repos\\personal-music-gen\\notebooks\\train_test.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautocast(device_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     lm_output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlm\u001b[39m.\u001b[39mcompute_predictions(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         codes\u001b[39m=\u001b[39mcodes,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         conditions\u001b[39m=\u001b[39m[],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         condition_tensors\u001b[39m=\u001b[39mconditional_vector\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     loss \u001b[39m=\u001b[39m compute_masked_loss(lm_output, codes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     scaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Paarth%20Tandon/Desktop/repos/personal-music-gen/notebooks/train_test.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\Desktop\\repos\\personal-music-gen\\personal_musicgen\\model_utils.py:37\u001b[0m, in \u001b[0;36mcompute_masked_loss\u001b[1;34m(lm_output, codes)\u001b[0m\n\u001b[0;32m     35\u001b[0m codes \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mone_hot(codes, \u001b[39m2048\u001b[39m)\u001b[39m.\u001b[39mtype(logits\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m     36\u001b[0m mask \u001b[39m=\u001b[39m mask\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m masked_logits \u001b[39m=\u001b[39m logits\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m2048\u001b[39;49m)[mask]\n\u001b[0;32m     38\u001b[0m masked_codes \u001b[39m=\u001b[39m codes\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2048\u001b[39m)[mask]\n\u001b[0;32m     40\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_step(model, optimizer, scaler, dataloader, acc_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
